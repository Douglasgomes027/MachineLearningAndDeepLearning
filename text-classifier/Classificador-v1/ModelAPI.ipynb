{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    return \"Hello World! <strong>I am learning Flask</strong>\", 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.route(\"/\", methods = ['POST'])\n",
    "def apicall():\n",
    "     \"\"\"API Call\n",
    "\n",
    "    Pandas dataframe (sent as a payload) from API Call\n",
    "    \"\"\"\n",
    "    try:\n",
    "        test_json = request.get_json()\n",
    "        test = pd.read_json(test_json, orient='records')\n",
    "\n",
    "        #To resolve the issue of TypeError: Cannot compare types 'ndarray(dtype=int64)' and 'str'\n",
    "        test['Dependents'] = [str(x) for x in list(test['Dependents'])]\n",
    "\n",
    "        #Getting the Loan_IDs separated out\n",
    "        loan_ids = test['Loan_ID']\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    clf = 'model_v1.pkl'\n",
    "    vocab = 'model_vocabulary.pkl'\n",
    "    if test.empty:\n",
    "        return(bad_request())\n",
    "    else:\n",
    "        #Load the saved model\n",
    "        print(\"Loading the model...\")\n",
    "        loaded_model = None\n",
    "        with open(clf,'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "            \n",
    "        print(\"Loading the vocabulary...\")\n",
    "        loaded_vocabulary = None\n",
    "        with open(vocab,'rb') as f2:\n",
    "            loaded_vocabulary = pickle.load(f2)\n",
    "        \n",
    "        vectorizer= CountVectorizer(vocabulary=loaded_vocabulary)\n",
    "        teste_predict_vect = vectorizer.transform(test) \n",
    "        \n",
    "        print(\"The model and vocabulary has been loaded...doing predictions now...\")\n",
    "        predictions = loaded_model.predict(teste_predict_vect)\n",
    "\n",
    "        \"\"\"Add the predictions as Series to a new pandas dataframe\n",
    "                                OR\n",
    "           Depending on the use-case, the entire test data appended with the new files\n",
    "        \"\"\"\n",
    "        prediction_series = list(pd.Series(predictions))\n",
    "\n",
    "        final_predictions = pd.DataFrame(list(zip(loan_ids, prediction_series)))\n",
    "\n",
    "        \"\"\"We can be as creative in sending the responses.\n",
    "           But we need to send the response codes as well.\n",
    "        \"\"\"\n",
    "        responses = jsonify(predictions=final_predictions.to_json(orient=\"records\"))\n",
    "        responses.status_code = 200\n",
    "\n",
    "        return (responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'model_v1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(filename ,'rb') as f:\n",
    "    loaded_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_filename = 'model_vocabulary.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(vocab_filename, 'rb') as f2:\n",
    "    loaded_vocabulary = joblib.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_train = CountVectorizer(vocabulary=loaded_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_predict=['EPSON MAGENTO','LILLO BICO','BOV AMERICANA KG','KING 100ML JASMIM']\n",
    "teste_predict_vect = vectorizer_train.transform(teste_predict) \n",
    "loaded_model.predict(teste_predict_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
